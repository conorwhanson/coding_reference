{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a18988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8645302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Python 3.9's help utility!\n",
      "\n",
      "If this is your first time using Python, you should definitely check out\n",
      "the tutorial on the Internet at https://docs.python.org/3.9/tutorial/.\n",
      "\n",
      "Enter the name of any module, keyword, or topic to get help on writing\n",
      "Python programs and using Python modules.  To quit this help utility and\n",
      "return to the interpreter, just type \"quit\".\n",
      "\n",
      "To get a list of available modules, keywords, symbols, or topics, type\n",
      "\"modules\", \"keywords\", \"symbols\", or \"topics\".  Each module also comes\n",
      "with a one-line summary of what it does; to list the modules whose name\n",
      "or summary contain a given string such as \"spam\", type \"modules spam\".\n",
      "\n",
      "help> value_counts()\n",
      "No Python documentation found for 'value_counts()'.\n",
      "Use help() to get the interactive help utility.\n",
      "Use help(str) for help on the str class.\n",
      "\n",
      "help> modules\n",
      "\n",
      "Please wait a moment while I gather a list of all available modules...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The private astropy._erfa module has been made into its own package, pyerfa, which is a dependency of astropy and can be imported directly using \"import erfa\" [astropy._erfa]\n",
      "/Users/conorhanson/opt/anaconda3/lib/python3.9/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\n",
      "/Users/conorhanson/opt/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "No QCoreApplication instance found. Application patches not applied. You have to call load_stylesheet function after instantiation of QApplication to take effect. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update LANGUAGE_CODES (inside config/base.py) if a new translation has been added to Spyder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conorhanson/opt/anaconda3/lib/python3.9/pkgutil.py:108: VisibleDeprecationWarning:\n",
      "\n",
      "zmq.eventloop.minitornado is deprecated in pyzmq 14.0 and will be removed.\n",
      "    Install tornado itself to use zmq with the tornado IOLoop.\n",
      "    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cython              cProfile            jupyterlab_plotly   rope\n",
      "IPython             cachetools          jupyterlab_pygments rsa\n",
      "OpenSSL             calendar            jupyterlab_server   rtree\n",
      "PIL                 certifi             jupyterlab_widgets  ruamel_yaml\n",
      "PyQt5               cffi                jwt                 runpy\n",
      "TBB                 cgi                 keyring             s3transfer\n",
      "__future__          cgitb               keyword             sched\n",
      "_abc                chardet             kiwisolver          scipy\n",
      "_aix_support        charset_normalizer  lazy_object_proxy   scrapy\n",
      "_argon2_cffi_bindings chunk               lib2to3             seaborn\n",
      "_ast                click               libarchive          secrets\n",
      "_asyncio            cloudpickle         libfuturize         select\n",
      "_bisect             clyent              libpasteurize       selectors\n",
      "_black_version      cmath               lief                selenium\n",
      "_blake2             cmd                 linecache           send2trash\n",
      "_bootlocale         code                llvmlite            service_identity\n",
      "_bootsubprocess     codecs              locale              setuptools\n",
      "_bz2                codeop              locket              shelve\n",
      "_cffi_backend       collections         logging             shlex\n",
      "_codecs             colorama            lxml                shutil\n",
      "_codecs_cn          colorcet            lz4                 signal\n",
      "_codecs_hk          colorsys            lzma                sipbuild\n",
      "_codecs_iso2022     compileall          mactypes            sipconfig\n",
      "_codecs_jp          concurrent          mailbox             sipdistutils\n",
      "_codecs_kr          conda               mailcap             site\n",
      "_codecs_tw          conda_build         markdown            six\n",
      "_collections        conda_content_trust markupsafe          skimage\n",
      "_collections_abc    conda_env           marshal             sklearn\n",
      "_compat_pickle      conda_pack          math                slugify\n",
      "_compression        conda_package_handling matplotlib          smart_open\n",
      "_contextvars        conda_token         matplotlib_inline   smtpd\n",
      "_crypt              conda_verify        mccabe              smtplib\n",
      "_csv                configparser        mimetypes           snappy\n",
      "_ctypes             constantly          mistune             sndhdr\n",
      "_ctypes_test        contextlib          mmap                sniffio\n",
      "_curses             contextvars         mock                snowballstemmer\n",
      "_curses_panel       cookiecutter        modulefinder        socket\n",
      "_datetime           copy                mpmath              socketserver\n",
      "_dbm                copyreg             msgpack             socks\n",
      "_decimal            crypt               multidict           sockshandler\n",
      "_distutils_hack     cryptography        multipledispatch    sortedcollections\n",
      "_elementtree        cssselect           multiprocessing     sortedcontainers\n",
      "_functools          csv                 munkres             soupsieve\n",
      "_hashlib            ctypes              mypy_extensions     sphinx\n",
      "_heapq              curl                navigator_updater   splinter\n",
      "_imp                curses              nbclassic           spyder\n",
      "_io                 cycler              nbclient            spyder_kernels\n",
      "_json               cython              nbconvert           sqlalchemy\n",
      "_locale             cytoolz             nbformat            sqlite3\n",
      "_lsprof             dask                nest_asyncio        sre_compile\n",
      "_lzma               dataclasses         netrc               sre_constants\n",
      "_markupbase         datashader          networkx            sre_parse\n",
      "_md5                datashape           newsapi             ssl\n",
      "_multibytecodec     datetime            nis                 stack_data\n",
      "_multiprocessing    dateutil            nltk                stat\n",
      "_opcode             dbm                 nntplib             statistics\n",
      "_operator           debugpy             nose                statsmodels\n",
      "_osx_support        decimal             notebook            string\n",
      "_peg_parser         decorator           ntpath              stringprep\n",
      "_pickle             defusedxml          nturl2path          struct\n",
      "_plotly_future_     diff_match_patch    numba               subprocess\n",
      "_plotly_utils       difflib             numbergen           sunau\n",
      "_posixshmem         dis                 numbers             symbol\n",
      "_posixsubprocess    distributed         numexpr             sympy\n",
      "_py_abc             distutils           numpy               symtable\n",
      "_pydecimal          doctest             numpydoc            sys\n",
      "_pyio               docutils            olefile             sysconfig\n",
      "_pyrsistent_version dotenv              opcode              syslog\n",
      "_pytest             email               openpyxl            tables\n",
      "_queue              encodings           operator            tabnanny\n",
      "_random             ensurepip           optparse            tabulate\n",
      "_scproxy            entrypoints         os                  tarfile\n",
      "_sha1               enum                osax                tbb\n",
      "_sha256             erfa                outcome             tblib\n",
      "_sha3               errno               packaging           telnetlib\n",
      "_sha512             et_xmlfile          pandas              tempfile\n",
      "_signal             executing           pandocfilters       tenacity\n",
      "_sitebuiltins       fastjsonschema      panel               terminado\n",
      "_socket             faulthandler        param               termios\n",
      "_sqlite3            fcntl               parsel              test\n",
      "_sre                filecmp             parser              test_pycosat\n",
      "_ssl                fileinput           parso               testpath\n",
      "_stat               filelock            partd               tests_negative\n",
      "_statistics         flake8              past                text_unidecode\n",
      "_string             flask               pathlib             textdistance\n",
      "_strptime           flask_pymongo       pathspec            textwrap\n",
      "_struct             fnmatch             patsy               this\n",
      "_symtable           fontTools           pdb                 threading\n",
      "_sysconfigdata__darwin_darwin formatter           pep8                threadpoolctl\n",
      "_sysconfigdata_arm64_apple_darwin20_0_0 fractions           pexpect             three_merge\n",
      "_testbuffer         frozenlist          pickle              tifffile\n",
      "_testcapi           fsspec              pickleshare         time\n",
      "_testimportmultiple ftplib              pickletools         timeit\n",
      "_testinternalcapi   functools           pip                 tinycss\n",
      "_testmultiphase     future              pipes               tkinter\n",
      "_thread             gc                  pkg_resources       tldextract\n",
      "_threading_local    genericpath         pkginfo             tlz\n",
      "_tkinter            gensim              pkgutil             token\n",
      "_tracemalloc        getopt              platform            tokenize\n",
      "_uuid               getpass             plistlib            toml\n",
      "_warnings           gettext             plotly              tomli\n",
      "_watchdog_fsevents  glob                pluggy              toolz\n",
      "_weakref            glob2               poplib              tornado\n",
      "_weakrefset         gmpy2               posix               tqdm\n",
      "_xxsubinterpreters  google_crc32c       posixpath           trace\n",
      "_xxtestfuzz         graphlib            poyo                traceback\n",
      "_yaml               greenlet            pprint              tracemalloc\n",
      "_zoneinfo           gridfs              profile             traitlets\n",
      "abc                 grp                 prometheus_client   trio\n",
      "aem                 grpc                prompt_toolkit      trio_websocket\n",
      "aifc                gzip                protego             tty\n",
      "aiohttp             h11                 pstats              turtle\n",
      "aiosignal           h5py                psutil              turtledemo\n",
      "alabaster           hamcrest            pty                 twisted\n",
      "anaconda_navigator  hashlib             ptyprocess          typed_ast\n",
      "anaconda_project    heapdict            pure_eval           types\n",
      "antigravity         heapq               pvectorc            typing\n",
      "anyio               hmac                pwd                 typing_extensions\n",
      "appdirs             holoviews           py                  ujson\n",
      "applaunchservices   html                py_compile          unicodedata\n",
      "appnope             html5lib            pyasn1              unidecode\n",
      "appscript           http                pyasn1_modules      unittest\n",
      "argon2              hvplot              pyclbr              urllib\n",
      "argparse            hyperlink           pycodestyle         urllib3\n",
      "array               idlelib             pycosat             useful_python_code\n",
      "arrow               idna                pycparser           uu\n",
      "ast                 imagecodecs         pyct                uuid\n",
      "astroid             imageio             pycurl              venv\n",
      "astropy             imagesize           pydispatch          w3lib\n",
      "asttokens           imaplib             pydoc               warnings\n",
      "async_generator     imblearn            pydoc_data          watchdog\n",
      "async_timeout       imghdr              pydocstyle          wave\n",
      "asynchat            imp                 pyexpat             wcwidth\n",
      "asyncio             importlib           pyflakes            weakref\n",
      "asyncore            importlib_metadata  pygments            webbrowser\n",
      "atexit              incremental         pylab               webdriver_manager\n",
      "atomicwrites        inflection          pylint              webencodings\n",
      "attr                iniconfig           pyls_spyder         websocket\n",
      "attrs               inspect             pylsp               werkzeug\n",
      "audioop             intake              pylsp_black         wheel\n",
      "automat             intervaltree        pylsp_jsonrpc       widgetsnbextension\n",
      "autopep8            io                  pymongo             wrapt\n",
      "babel               ipaddress           pyodbc              wsgiref\n",
      "backcall            ipykernel           pyparsing           wsproto\n",
      "backports           ipykernel_launcher  pyrsistent          wurlitzer\n",
      "base64              ipython_genutils    pytest              xarray\n",
      "bcrypt              ipywidgets          pytz                xdrlib\n",
      "bdb                 isort               pyviz_comms         xlrd\n",
      "binaryornot         isympy              pywt                xlsxwriter\n",
      "binascii            itemadapter         pyximport           xlwings\n",
      "binhex              itemloaders         qdarkstyle          xml\n",
      "binstar_client      itertools           qstylizer           xmlrpc\n",
      "bisect              itsdangerous        qtawesome           xxlimited\n",
      "bitarray            jdcal               qtconsole           xxsubtype\n",
      "bkcharts            jedi                qtpy                yaml\n",
      "black               jinja2              queue               yapf\n",
      "blackd              jinja2_time         queuelib            yapftests\n",
      "bleach              jmespath            quopri              yarl\n",
      "blib2to3            joblib              random              zict\n",
      "bokeh               json                re                  zipapp\n",
      "boto3               json5               readline            zipfile\n",
      "botocore            jsonschema          regex               zipimport\n",
      "bottleneck          jupyter             repo_cli            zipp\n",
      "brotli              jupyter_client      reprlib             zlib\n",
      "bs4                 jupyter_console     requests            zmq\n",
      "bson                jupyter_core        requests_file       zoneinfo\n",
      "builtins            jupyter_server      resource            zope\n",
      "bz2                 jupyterlab          rlcompleter         \n",
      "\n",
      "Enter any module name to get more help.  Or, type \"modules spam\" to search\n",
      "for modules whose name or summary contain the string \"spam\".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help> sklearn\n",
      "Help on package sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn\n",
      "\n",
      "DESCRIPTION\n",
      "    Machine learning module for Python\n",
      "    ==================================\n",
      "    \n",
      "    sklearn is a Python module integrating classical machine\n",
      "    learning algorithms in the tightly-knit world of scientific Python\n",
      "    packages (numpy, scipy, matplotlib).\n",
      "    \n",
      "    It aims to provide simple and efficient solutions to learning problems\n",
      "    that are accessible to everybody and reusable in various contexts:\n",
      "    machine-learning as a versatile tool for science and engineering.\n",
      "    \n",
      "    See http://scikit-learn.org for complete documentation.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __check_build (package)\n",
      "    _build_utils (package)\n",
      "    _config\n",
      "    _distributor_init\n",
      "    _isotonic\n",
      "    _loss (package)\n",
      "    _min_dependencies\n",
      "    base\n",
      "    calibration\n",
      "    cluster (package)\n",
      "    compose (package)\n",
      "    conftest\n",
      "    covariance (package)\n",
      "    cross_decomposition (package)\n",
      "    datasets (package)\n",
      "    decomposition (package)\n",
      "    discriminant_analysis\n",
      "    dummy\n",
      "    ensemble (package)\n",
      "    exceptions\n",
      "    experimental (package)\n",
      "    externals (package)\n",
      "    feature_extraction (package)\n",
      "    feature_selection (package)\n",
      "    gaussian_process (package)\n",
      "    impute (package)\n",
      "    inspection (package)\n",
      "    isotonic\n",
      "    kernel_approximation\n",
      "    kernel_ridge\n",
      "    linear_model (package)\n",
      "    manifold (package)\n",
      "    metrics (package)\n",
      "    mixture (package)\n",
      "    model_selection (package)\n",
      "    multiclass\n",
      "    multioutput\n",
      "    naive_bayes\n",
      "    neighbors (package)\n",
      "    neural_network (package)\n",
      "    pipeline\n",
      "    preprocessing (package)\n",
      "    random_projection\n",
      "    semi_supervised (package)\n",
      "    setup\n",
      "    svm (package)\n",
      "    tests (package)\n",
      "    tree (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clone(estimator, *, safe=True)\n",
      "        Construct a new unfitted estimator with the same parameters.\n",
      "        \n",
      "        Clone does a deep copy of the model in an estimator\n",
      "        without actually copying attached data. It returns a new estimator\n",
      "        with the same parameters that has not been fitted on any data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : {list, tuple, set} of estimator instance or a single             estimator instance\n",
      "            The estimator or group of estimators to be cloned.\n",
      "        safe : bool, default=True\n",
      "            If safe is False, clone will fall back to a deep copy on objects\n",
      "            that are not estimators.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        estimator : object\n",
      "            The deep copy of the input, an estimator if input is an estimator.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If the estimator's `random_state` parameter is an integer (or if the\n",
      "        estimator doesn't have a `random_state` parameter), an *exact clone* is\n",
      "        returned: the clone and the original estimator will give the exact same\n",
      "        results. Otherwise, *statistical clone* is returned: the clone might\n",
      "        return different results from the original estimator. More details can be\n",
      "        found in :ref:`randomness`.\n",
      "    \n",
      "    config_context(*, assume_finite=None, working_memory=None, print_changed_only=None, display=None, pairwise_dist_chunk_size=None, enable_cython_pairwise_dist=None)\n",
      "        Context manager for global scikit-learn configuration.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, default=None\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error. If None, the existing value won't change.\n",
      "            The default value is False.\n",
      "        \n",
      "        working_memory : int, default=None\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. If None, the existing value won't change.\n",
      "            The default value is 1024.\n",
      "        \n",
      "        print_changed_only : bool, default=None\n",
      "            If True, only the parameters that were set to non-default\n",
      "            values will be printed when printing an estimator. For example,\n",
      "            ``print(SVC())`` while True will only print 'SVC()', but would print\n",
      "            'SVC(C=1.0, cache_size=200, ...)' with all the non-changed parameters\n",
      "            when False. If None, the existing value won't change.\n",
      "            The default value is True.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Default changed from False to True.\n",
      "        \n",
      "        display : {'text', 'diagram'}, default=None\n",
      "            If 'diagram', estimators will be displayed as a diagram in a Jupyter\n",
      "            lab or notebook context. If 'text', estimators will be displayed as\n",
      "            text. If None, the existing value won't change.\n",
      "            The default value is 'diagram'.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        pairwise_dist_chunk_size : int, default=None\n",
      "            The number of vectors per chunk for PairwiseDistancesReduction.\n",
      "            Default is 256 (suitable for most of modern laptops' caches and architectures).\n",
      "        \n",
      "            Intended for easier benchmarking and testing of scikit-learn internals.\n",
      "            End users are not expected to benefit from customizing this configuration\n",
      "            setting.\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        enable_cython_pairwise_dist : bool, default=None\n",
      "            Use PairwiseDistancesReduction when possible.\n",
      "            Default is True.\n",
      "        \n",
      "            Intended for easier benchmarking and testing of scikit-learn internals.\n",
      "            End users are not expected to benefit from customizing this configuration\n",
      "            setting.\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        Yields\n",
      "        ------\n",
      "        None.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        set_config : Set global scikit-learn configuration.\n",
      "        get_config : Retrieve current values of the global configuration.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All settings, not just those presently modified, will be returned to\n",
      "        their previous values when the context manager is exited.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import sklearn\n",
      "        >>> from sklearn.utils.validation import assert_all_finite\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     assert_all_finite([float('nan')])\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     with sklearn.config_context(assume_finite=False):\n",
      "        ...         assert_all_finite([float('nan')])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Input contains NaN...\n",
      "    \n",
      "    get_config()\n",
      "        Retrieve current values for configuration set by :func:`set_config`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        config : dict\n",
      "            Keys are parameter names that can be passed to :func:`set_config`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        config_context : Context manager for global scikit-learn configuration.\n",
      "        set_config : Set global scikit-learn configuration.\n",
      "    \n",
      "    set_config(assume_finite=None, working_memory=None, print_changed_only=None, display=None, pairwise_dist_chunk_size=None, enable_cython_pairwise_dist=None)\n",
      "        Set global scikit-learn configuration\n",
      "        \n",
      "        .. versionadded:: 0.19\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, default=None\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error.  Global default: False.\n",
      "        \n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        working_memory : int, default=None\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. Global default: 1024.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        print_changed_only : bool, default=None\n",
      "            If True, only the parameters that were set to non-default\n",
      "            values will be printed when printing an estimator. For example,\n",
      "            ``print(SVC())`` while True will only print 'SVC()' while the default\n",
      "            behaviour would be to print 'SVC(C=1.0, cache_size=200, ...)' with\n",
      "            all the non-changed parameters.\n",
      "        \n",
      "            .. versionadded:: 0.21\n",
      "        \n",
      "        display : {'text', 'diagram'}, default=None\n",
      "            If 'diagram', estimators will be displayed as a diagram in a Jupyter\n",
      "            lab or notebook context. If 'text', estimators will be displayed as\n",
      "            text. Default is 'diagram'.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        pairwise_dist_chunk_size : int, default=None\n",
      "            The number of row vectors per chunk for PairwiseDistancesReduction.\n",
      "            Default is 256 (suitable for most of modern laptops' caches and architectures).\n",
      "        \n",
      "            Intended for easier benchmarking and testing of scikit-learn internals.\n",
      "            End users are not expected to benefit from customizing this configuration\n",
      "            setting.\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        enable_cython_pairwise_dist : bool, default=None\n",
      "            Use PairwiseDistancesReduction when possible.\n",
      "            Default is True.\n",
      "        \n",
      "            Intended for easier benchmarking and testing of scikit-learn internals.\n",
      "            End users are not expected to benefit from customizing this configuration\n",
      "            setting.\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        config_context : Context manager for global scikit-learn configuration.\n",
      "        get_config : Retrieve current values of the global configuration.\n",
      "    \n",
      "    show_versions()\n",
      "        Print useful debugging information\"\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "DATA\n",
      "    __SKLEARN_SETUP__ = False\n",
      "    __all__ = ['calibration', 'cluster', 'covariance', 'cross_decompositio...\n",
      "\n",
      "VERSION\n",
      "    1.1.1\n",
      "\n",
      "FILE\n",
      "    /Users/conorhanson/opt/anaconda3/lib/python3.9/site-packages/sklearn/__init__.py\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help> quit\n",
      "\n",
      "You are now leaving help and returning to the Python interpreter.\n",
      "If you want to ask for help on a particular object directly from the\n",
      "interpreter, you can type \"help(object)\".  Executing \"help('string')\"\n",
      "has the same effect as typing a particular string at the help> prompt.\n"
     ]
    }
   ],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80e173da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def late(x, name):\n",
    "    order = x.index(name)\n",
    "    if order >= len(x) / 2:\n",
    "        print(f\"{x[0]}, {x[1]}, and {x[2]} hate your guts {name}. Don't be late again\")\n",
    "    else:\n",
    "        return \"Welcome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e893caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe, Alex, and Katie hate your guts Sam. Don't be late again\n"
     ]
    }
   ],
   "source": [
    "peeps = ['Joe', 'Alex', 'Katie', 'Sam', 'Alan']\n",
    "\n",
    "late(peeps, 'Sam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7d262408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_negatives(nums):\n",
    "    return len([num for num in nums if num < 0])\n",
    "\n",
    "#  or\n",
    "def count_neg_short(nums):\n",
    "    return sum([num < 0 for num in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f02377aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [0, -4, -89, -65, 1]\n",
    "\n",
    "count_neg_short(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3030f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_lucky_number(nums):\n",
    "    \"\"\"Return whether the given list of numbers is lucky. A lucky list contains\n",
    "    at least one number divisible by 7.\n",
    "    \"\"\"\n",
    "    for num in nums:\n",
    "        if num % 7 == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# OR\n",
    "def has_lucky_short(nums):\n",
    "    return any([num % 7 == 0 for num in nums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c788143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yup = [7, 4, 8, 1]\n",
    "\n",
    "has_lucky_short(yup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b5245eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementwise_greater_than(L, thresh):\n",
    "    \"\"\"Return a list with the same length as L, where the value at index i is \n",
    "    True if L[i] is greater than thresh, and False otherwise.\n",
    "    \n",
    "    >>> elementwise_greater_than([1, 2, 3, 4], 2)\n",
    "    [False, False, True, True]\n",
    "    \"\"\"\n",
    "    big_bool = []\n",
    "    for n in L:\n",
    "        big_bool.append(n > thresh)\n",
    "    return big_bool\n",
    "# OR\n",
    "def elementwise_greater_than(L, thresh):\n",
    "    return [n > thresh for n in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7f23ce33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pluto weighs about 1.3e+22 kilograms (0.218% of Earth's mass). It is home to 52,910,390 Plutonians.\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planet = 'Pluto'\n",
    "pluto_mass = 1.303 * 10**22\n",
    "earth_mass = 5.9722 * 10**24\n",
    "population = 52910390\n",
    "#         2 decimal points   3 decimal points, format as percent     separate with commas\n",
    "\"{} weighs about {:.2} kilograms ({:.3%} of Earth's mass). It is home to {:,} Plutonians.\".format(\n",
    "    planet, pluto_mass, pluto_mass / earth_mass, population,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "261f243a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mercury': 'M',\n",
       " 'Venus': 'V',\n",
       " 'Earth': 'E',\n",
       " 'Mars': 'M',\n",
       " 'Jupiter': 'J',\n",
       " 'Saturn': 'S',\n",
       " 'Uranus': 'U',\n",
       " 'Neptune': 'N'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets = ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']\n",
    "planet_to_initial = {planet: planet[0] for planet in planets}\n",
    "planet_to_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a6a7efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_zip(zip, x, y):\n",
    "    for z in zip:\n",
    "        if len(z) == 5 and z.isdigit():\n",
    "            x.append(z)\n",
    "        else:\n",
    "            y.append(z)\n",
    "    return f\"Valid: {x} Invalid: {y}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0ac114c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Valid: ['53421', '55303'] Invalid: ['apple']\""
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yep = []\n",
    "nope = []\n",
    "zips = [\"53421\", \"apple\", \"55303\"]\n",
    "valid_zip(zips, yep, nope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "65f9cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_search(doc_list, keyword):\n",
    "    # list to hold the indices of matching documents\n",
    "    indices = [] \n",
    "    # Iterate through the indices (i) and elements (doc) of documents\n",
    "    for i, doc in enumerate(doc_list):\n",
    "        # Split the string doc into a list of words (according to whitespace)\n",
    "        tokens = doc.split()\n",
    "        # Make a transformed list where we 'normalize' each word to facilitate matching.\n",
    "        # Periods and commas are removed from the end of each word, and it's set to all lowercase.\n",
    "        normalized = [token.strip('.,').lower() for token in tokens]\n",
    "        # Is there a match? If so, update the list of matching indices.\n",
    "        if keyword.lower() in normalized:\n",
    "            indices.append(i)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ed32b00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [\"The Learn Python Challenge Casino.\", \"They bought a car\", \"Casinoville\"]\n",
    "\n",
    "word_search(sent, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b85322cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_word_search(documents, keywords):\n",
    "    keyword_to_indices = {}\n",
    "    for keyword in keywords:\n",
    "        keyword_to_indices[keyword] = word_search(documents, keyword)\n",
    "    return keyword_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8a4ec85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': [0], 'car': [1]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['learn', 'car']\n",
    "multi_word_search(sent, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7d27a1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1404, 1469,  521,  250, 1029,  662, 1216,    2,  570,  875])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls = np.random.randint(low=1, high=1598, size=10)\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4e4f5414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a4e9fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_function__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n"
     ]
    }
   ],
   "source": [
    "print(dir(rolls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "54831726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7998"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_rolls = sum(rolls)\n",
    "sum_rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "911d767d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1404, 1469, 521, 250, 1029, 662, 1216, 2, 570, 875]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7db5149e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1404"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "462c2eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False,  True, False,  True, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls >= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2b261d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1404, 1469, 521, 250, 1029, 662, 1216, 2, 570, 875]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f65c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
